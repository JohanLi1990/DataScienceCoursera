swirl()
swirl()
library("swirl")
swirl()
install_course("Regression Models")
swirl()
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
bye()
library("swirl")
ls()
rm(list = ls())
swirl()
sA
sA[, 2]
InsectSprays[,2]
summary(InsectSprays[,2])
sap
sapply(InsectSprays[, 2])
info()
sapply(InsectSprays[, 2], FUN = class())
sapply(InsectSprays[, 2], FUN = class(InsectSprays))
sapply(InsectSprays, class)
lm(count ~ spray, InsectSprays)
fit <- lm(count ~ spray, InsectSprays)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit<-lm(count ~ spray - 1, InsectSprays)
nfit$coefficients
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2<- lm(count ~ spray, spray2)
fit2<- lm(InsectSprays$count ~ spray2)
summary(fit2)$coef
mean(sC)
(fit$coef[2] - fit$coef[3])/1.6011
rm(list = ls())
swirl()
dim(hunger)
948
names(hunger[, 13])
names(hunger)
fit <- lm(Numeric~Year, hunger)
coef(fit)
summary(fit)$coef
hunger$Numeric
lmf<-lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"], hunger)
lmF<-lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"], hunger)
lmM<-lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"], hunger)
lmBoth <- lm(Numeric ~ Year + Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, hunger)
summary(lmInter)
swirl()
library(swirl)
rm(list = ls())
swirl()
swirl()
fit<-lm(y~x, out2)
plot(fit, which = 1)
fitno<-lm(y~x, out2[-1,])
plot(fitno, which = 1)
coef(fit) -coef(fitno)
head(dfbeta(fit))
resno<-out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
info()
play()
resno
out2[1, "y"]
out2[1, 0]
out2[1,]
predict(fitno, out2[1,])
nxt
nxt()
head(hatvalues(fit))
ssm(fit$residuals)
fit$residuals
sigma<-sqrt(deviance(fit)/df.residual(fit))
play()
df.residual(fit)
?df.residual
?deviance
nxt()
rstd<-resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which = 3)
plot(fit, which = 2)
sigma1<- sqrt(deviance(fitno)/df.residual((fitno)))
resid(fit1)[1]/(sigma1 * sqrt(1-hatvalues(fit)[1]))
resid(fit)[1]/(sigma1 * sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
library("swirl")
swirl()
head(swiss)
mdl <- lm(Fertility ~., swiss)
vif(mdl)
mdl2<-lm(Fertility ~ .)
mdl2<-lm(Fertility ~., swiss)
mdl2<-lm(Fertility ~ .-Examination, swiss)
vif(mdl2)
swirl
swirl()
x1c<-simbias()
bye()
rm(ls = list())
rm(list = ls())
swirl()
simbias();apply(z1c, 1, mean)
simbias();apply(x1c, 1, mean)
apply(x1c, 1, mean)
x1c<-simbias();apply(x1c, 1, mean)
fi1<-lm(Fertility ~ Agriculture, swiss)
fit1<-lm(Fertility ~ Agriculture, swiss)
fit3<-lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d<-deviance(fit3)/43
n<-(deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
swirl()
view(ravenData)
View(ravenData)
mdl<-glm(ravenWinNum ~ ravenScore, family = "binomial", ravenData)
lodds<-predict(mdl, data.frame(ravenScore = c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
library("swirl")
swirl()
install_course("Exploratory_Data_Analysis")
install_course("Mathematical_Biostatistics_Boot_Camp")
install_course("Mathematical_Biostatistics_Boot_Camp")
install_course("Mathematical_Biostatistics_Boot_Camp")
install_course("R_Programming_Alt")
library(swirl)
install_course("R_Programming_Al")
install_course("R_Programming_Alt")
install_course("Data_Analysis")
install_course("Data Analysis")
install_course("R_Programming")
library(caret)
?`caret-internal`
rm(list = ls())
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
dim(training)
?createDataPartition
?set.seed
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,
list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds
View(folds)
View(folds)
4141/4601
4601 - 4141
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training, method="glm")
fit <- lm()
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training, method="glm")
install.packages('e1071', dependencies=TRUE)
install.packages('e1071', dependencies=TRUE)
modelFit <- train(type ~.,data=training, method="glm")
warnings()
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
install.packages("ISLR")
library(ISLR); library(ggplot2); library(caret); library(gridExtra);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
rm(list = ls())
library(caret)
library(mlbench)
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class, p = 0.75, list = FALSE)
str(inTrain)
training <- Sonar[inTrain, ]
testing <- Sonar[-inTrain, ]
nrow(training)
nrow(testing)
plsFit <- train( Clas ~., data = training, method = "pls", preProc = c("center", "scale"))
plsFit <- train(Class ~., data = training, method = "pls", preProc = c("center", "scale"))
?train
summary(plsFit)
plsFit$method
plsFit
sensitivity(plsFit)
library(kernlab)
data(spam)
?spam
install.packages("rattle")
install.packages("rattle")
install.packages("RGtk2Extras")
install.packages("RGtk2")
install.packages(c("brglm", "curl", "DBI", "dplyr", "evaluate", "GGally", "jsonlite", "quantmod", "R6", "rJava", "rmarkdown", "RSQLite", "sqldf", "tibble", "XML"))
install.packages(c("brglm", "curl", "DBI", "dplyr", "evaluate", "GGally", "jsonlite", "quantmod", "R6", "rJava", "rmarkdown", "RSQLite", "sqldf", "tibble", "XML"))
install.packages(c("brglm", "curl", "DBI", "dplyr", "evaluate", "GGally", "jsonlite", "quantmod", "R6", "rJava", "rmarkdown", "RSQLite", "sqldf", "tibble", "XML"))
install.packages(c("brglm", "curl", "DBI", "dplyr", "evaluate", "GGally", "jsonlite", "quantmod", "R6", "rJava", "rmarkdown", "RSQLite", "sqldf", "tibble", "XML"))
library(rattle)
install.packages("rattle")
install.packages("rattle")
install.packages("RGtk2Extras")
install.packages("https://cran.r-project.org/src/contrib/Archive/RGtk2/RGtk2_2.20.31.tar.gz", repos=NULL)
install.packages("rattle")
library(rattle)
modFit<- train(Class~., method="rpart",data=training,verbose=FALSE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(ggplot2)
library(lattice)
library(caret)
library(rpart)
#Step 1: create data partition
training <- segmentationOriginal[segmentationOriginal$Case == "Train", ]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test", ]
#Step 2:Cart Model, seed = 125, rpart
set.seed(125)
modFit<- train(Class~., method="rpart",data=training,verbose=FALSE)
# Stpe 3 draw maps
library(rattle)
set.seed(125)
modFit<- train(Class~., method="rpart",data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
data(olive)
View(olive)
olive = olive[, -1]
modfit2<-train(Area ~., data = olive, method = "rpart")
?t
predict(modfit2, newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modfit3 <- train(chd ~ age + alcohol + obesity +tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass(trainSA$chd,predict(modfit3))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(modfit3))
missClass(trainSA$chd,predict(modfit3, testSA))
missClass(testSA$chd,predict(modfit3, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
modfit4 <- train(y ~., data = vowel.train, method = "rf")
varImp(modfit4)
set.seed(33833)
modfit4 <- train(y ~., data = vowel.train, method = "rf")
varImp(modfit4)
modfit4 <- randomForest(y ~., data = vowel.train)
varImp(modfit4)
varImp(modfit4, order = "decreasing")
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
rm(list  = ls())
library(caret);library(randomForest);library(rpart); library(rattle); library(plyr)
Training <-  read.csv("pml-training", header=TRUE, na.strings = c("NA","",'#DIV/0!'))
Testing <- read.csv("pml-testing",header=TRUE, na.strings = c("NA","",'#DIV/0!'))
Training<- Training[ , colSums(is.na(Training)) == 0]
Testing<- Testing[ , colSums(is.na(Testing)) == 0]
Training_preFinal <- Training[,-(1:7)]
Testing_preFinal<- Testing[,-(1:7)]
Testing_preFinal<-Testing_preFinal[, -53]
set.seed(123)
TrainingID <- createDataPartition(Training_preFinal$classe, p=0.75, list = F)
FinalTraining <- Training_preFinal[TrainingID,]
FinalValidation <- Training_preFinal[-TrainingID, ]
tr_ctrl <- trainControl(FinalTraining, method = "cv", number = 3)
model_gbm <- train(classe ~., data = FinalTraining, preProcess = c("center", "scale")
, trControl = tr_ctrl, method = "gbm", verbose = F)
gbm_pred <- predict(model_gbm, newdata = FinalTraining)
gbm_evaluation <- confusionMatrix(gbm_pred, FinalValidation$classe)
gbm_pred <- predict(model_gbm, newdata = FinalValidation)
gbm_evaluation <- confusionMatrix(gbm_pred, FinalValidation$classe)
gbm_evaluation
gbm_outta_sample_error <- 1 - gbm_evaluation$overall['Accuracy']
gbm_outta_sample_error
print(gbm_outta_sample_error)
rename(gbm_outta_sample_error, "out of sample error")
gbm_outta_sample_error <- 1 - gbm_evaluation$overall[1]
gbm_outta_sample_error
names(gbm_outta_sample_error)
names(gbm_outta_sample_error) <- "out of sample error"
gbm_outta_sample_error
names(gbm_outta_sample_error) <- "out of sample error for gbm"
gbm_outta_sample_error
set.seed(245)
tr_ctrl <- trainControl(FinalTraining, method = "cv", number = 3)
model_gbm <- train(classe ~., data = FinalTraining, preProcess = c("center", "scale")
, trControl = tr_ctrl, method = "gbm", verbose = F)
gbm_pred <- predict(model_gbm, newdata = FinalValidation)
gbm_evaluation <- confusionMatrix(gbm_pred, FinalValidation$classe)
gbm_outta_sample_error <- 1 - gbm_evaluation$overall[1]
names(gbm_outta_sample_error) <- "out of sample error for gbm"
gbm_outta_sample_error
set.seed(246)
model_rf <- train(classe ~., data = FinalTraining, method = "rf",
trControl = tr_ctrl, preProcess = c("center", "scale"))
rf_pred <- predict(model_rf, newdata = FinalValidation)
rf_evaluation <- confusionMatrix(rf_pred, FinalValidation$classe)
rf_outta_sample_error <- 1 - rf_evaluation$overall[1]
names(rf_outta_sample_error) <- "out of sample error for rf"
rf_outta_sample_error
rf_evaluation
model_rf$finalModel
model_rf
set.seed(246)
model_rf <- train(classe ~., data = FinalTraining, method = "rf",
trControl = tr_ctrl)
rf_pred <- predict(model_rf, newdata = FinalValidation)
rf_evaluation <- confusionMatrix(rf_pred, FinalValidation$classe)
rf_outta_sample_error <- 1 - rf_evaluation$overall[1]
names(rf_outta_sample_error) <- "out of sample error for rf"
rf_outta_sample_error
rf_test_pred <- pred(model_rf, newdata = Testing_preFinal)
rf_test_pred <- predict(model_rf, newdata = Testing_preFinal)
print(rf_test_pred)
rm(list = ls())
# make this an external chunk that can be included in any file
options(width = 100)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')
library(kernlab); data(spam); set.seed(333)
?spam
?sample
dim(spam)
sample(dim(spam)[1], size = 10)
sample(dim(spam)[1], size = 10)
smallSpam <- spam[sample(dim(spam)[1],size=10),]
spamLabel <- (smallSpam$type=="spam")*1 + 1
?spam
plot(smallSpam$capitalAve,col=spamLabel)
library(kernlab); data(spam); set.seed(333)
smallSpam <- spam[sample(dim(spam)[1],size=10),]
spamLabel <- (smallSpam$type=="spam")*1 + 1
plot(smallSpam$capitalAve,col=spamLabel)
plot(smallSpam$capitalAve,col=spamLabel)
View(smallSpam)
plot(smallSpam$capitalAve,col=smallSpam$type)
smallSpam$capitalAve > 2.4
load("/home/johan/Documents/courses/09_DevelopingDataProducts/plotly/courseraData.rda")
View(myData)
View(myData)
View(smallSpam)
View(spam)
install.packages("shiny")
shiny::runApp('Documents/DataScienceCoursera/Developing_Data_Product/MyApp')
runApp('Documents/DataScience_Materials/Developing Data Products_Github/Developing_Data_Products/Shiny_Part_2/app4')
library(shiny)
library(miniUI)
myFirstGadget <- function() {
ui <- miniPage(
gadgetTitleBar("My First Gadget")
)
server <- function(input, output, session) {
# The Done button closes the app
observeEvent(input$done, {
stopApp()
})
}
runGadget(ui, server)
}
install.packages("miniUI")
library(shiny)
library(miniUI)
myFirstGadget <- function() {
ui <- miniPage(
gadgetTitleBar("My First Gadget")
)
server <- function(input, output, session) {
# The Done button closes the app
observeEvent(input$done, {
stopApp()
})
}
runGadget(ui, server)
}
myFirstGadget()
library(shiny)
library(miniUI)
multiplyNumbers <- function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
selectInput("num1", "First Number", choices=numbers1),
selectInput("num2", "Second Number", choices=numbers2)
)
)
```
## Gadgets with Arguments: Code Part 2
```r
server <- function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 * num2)
})
}
runGadget(ui, server)
}
multiplyNumbers <- function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
selectInput("num1", "First Number", choices=numbers1),
selectInput("num2", "Second Number", choices=numbers2)
)
)
server <- function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 * num2)
})
}
runGadget(ui, server)
}
multiplyNumbers()
multiplyNumbers(10, 10)
multiplyNumbers(1:10, 1:10)
library(plotly)
data("airmiles")
plot_ly(x = ~time(airmiles), y = ~airmiles, type = "scatter", mode = "lines")
library(tidyr)
library(dplyr)
data("EuStockMarkets")
stocks <- as.data.frame(EuStockMarkets) %>%
gather(index, price) %>%
mutate(time = rep(time(EuStockMarkets), 4))
?mutate
plot_ly(x = ~precip, type = "histogram")
plot_ly(x = precip, type = "histogram")
# Create data frame
state_pop <- data.frame(State = state.abb, Pop = as.vector(state.x77[,1]))
?state
shiny::runApp('Documents/DataScience_Materials/Developing Data Products_Github/Developing_Data_Products/Shiny_Part_1/app1')
install.packages("leaflet")
library(leaflet)
my_map <- leaflet() %>%
addTiles()
my_map
my_map
my_map <- my_map %>%
addMarkers(lat=39.2980803, lng=57.5898801,
popup="my home")
my_map
setwd("~/Documents/DataScienceCoursera/Developing_Data_Product")
